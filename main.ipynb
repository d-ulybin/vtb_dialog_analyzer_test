{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!sudo apt install python3-dev\n",
    "!sudoapt install python3-venv\n",
    "!sudo apt install ffmpeg libavcodec-extra\n",
    "!python -m pip install requirements.txt\n",
    "!python -m pip install pyannote.audio==3.2.0\n",
    "!python -m pip install git+https://github.com/NVIDIA/NeMo.git@1fa961ba03ab5f8c91b278640e29807079373372#egg=nemo_toolkit[all]\n",
    "\n",
    "!wget https://n-ws-q0bez.s3pd12.sbercloud.ru/b-ws-q0bez-jpv/GigaAM/rnnt_model_weights.ckpt\n",
    "!wget https://n-ws-q0bez.s3pd12.sbercloud.ru/b-ws-q0bez-jpv/GigaAM/rnnt_model_config.yaml\n",
    "!wget https://n-ws-q0bez.s3pd12.sbercloud.ru/b-ws-q0bez-jpv/GigaAM/tokenizer_all_sets.tar\n",
    "\n",
    "!wget https://n-ws-q0bez.s3pd12.sbercloud.ru/b-ws-q0bez-jpv/GigaAM/emo_model_weights.ckpt\n",
    "!wget https://n-ws-q0bez.s3pd12.sbercloud.ru/b-ws-q0bez-jpv/GigaAM/emo_model_config.yaml\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda do_setlocale=True: \"UTF-8\"\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "\n",
    "import os\n",
    "from io import BytesIO\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import hydra\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torchaudio\n",
    "from deep_translator import GoogleTranslator\n",
    "from nemo.collections.asr.models import EncDecRNNTBPEModel\n",
    "\n",
    "from omegaconf import DictConfig, ListConfig, OmegaConf\n",
    "from pyannote.audio import Pipeline\n",
    "from pydub import AudioSegment\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, T5ForConditionalGeneration, T5Tokenizer, AutoModel\n",
    "\n",
    "from langchain import HuggingFacePipeline, PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "from src.gigamodels import SpecScaler, GigaAMEmo, FilterbankFeaturesTA, AudioToMelSpectrogramPreprocessor\n",
    "from src.youtubedownloader import YouTubeAudioDownloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Не стал выносить классы в отдельные модули для наглядности, в отдельный файл вынес заимствованные классы от Gigamodels, а также нерелевантный задаче класс youtube downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueSummarizer:\n",
    "    def __init__(self, model_name='d0rj/rut5-base-summ'):\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(model_name).eval()\n",
    "\n",
    "    def format_dialogue(self, transcriptions, speakers):\n",
    "        formatted_dialogue = []\n",
    "        for transcription, speaker in zip(transcriptions, speakers):\n",
    "            formatted_dialogue.append(f\"{speaker}: {transcription}\")\n",
    "        return '\\n'.join(formatted_dialogue)\n",
    "\n",
    "    def summarize(self, transcriptions, speakers):\n",
    "        formatted_text = self.format_dialogue(transcriptions, speakers)\n",
    "        input_ids = self.tokenizer(formatted_text, return_tensors='pt', max_length=512, truncation=True).input_ids\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(input_ids, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "        \n",
    "        summary = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return summary.strip()\n",
    "\n",
    "\n",
    "class QuestionDetector:\n",
    "    def __init__(self, model_name=\"Godfrey2712/amf_illoc_force_intent_recognition\"):\n",
    "        self.translator = GoogleTranslator(source='auto', target='en')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        self.question_intents = {3, 7}  # \"Assertive Questioning\", \"Pure Questioning\"\n",
    "\n",
    "    def is_question(self, text):\n",
    "        translated_text = self.translator.translate(text.lower())\n",
    "        intent = self.predict_intent(translated_text)\n",
    "        return intent in self.question_intents\n",
    "\n",
    "    def predict_intent(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\")\n",
    "        outputs = self.model(**inputs)\n",
    "        return torch.argmax(outputs.logits, dim=1).item()\n",
    "\n",
    "class QuestionHandler:\n",
    "    def __init__(self, model_name=\"IlyaGusev/saiga_tlite_8b\", knowledge_file=\"knowledge.txt\"):\n",
    "        self.model_name = model_name\n",
    "        self.knowledge_file = knowledge_file\n",
    "        self.llm = self._setup_llm()\n",
    "        self.knowledge_base = self._load_knowledge_base()\n",
    "        self.prompt_template = self._setup_prompt_template()\n",
    "        self.chain = self._setup_chain()\n",
    "\n",
    "    def _setup_llm(self):\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.model_name, use_fast=False)\n",
    "        model = AutoModelForCausalLM.from_pretrained(self.model_name, torch_dtype=torch.float16, low_cpu_mem_usage=True)\n",
    "        \n",
    "        \n",
    "        pipe = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            max_new_tokens=1000,\n",
    "            temperature=0.1,\n",
    "            top_p=0.95,\n",
    "            repetition_penalty=1.05,\n",
    "            device=0 if torch.cuda.is_available() else -1\n",
    "        )\n",
    "        \n",
    "        return HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "    def _load_knowledge_base(self):\n",
    "        try:\n",
    "            with open(self.knowledge_file, 'r', encoding='utf-8') as file:\n",
    "                return file.read()\n",
    "        except FileNotFoundError:\n",
    "            raise ValueError(f\"Knowledge file '{self.knowledge_file}' not found.\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading knowledge base: {e}\")\n",
    "\n",
    "    def _setup_prompt_template(self):\n",
    "        \n",
    "        template = f\"\"\"Вы Система, русскоязычный автоматический ассистент и помощником оператора контакт-центра. Используйте следующую информацию в качестве базы знаний:\n",
    "        {self.knowledge_base}\n",
    "        \n",
    "        Человек: Подготовь подсказку, как правильно оператору ответить на следующий вопрос: {{question}}\n",
    "        \n",
    "        Система: Вот рекомендация, как ответить на вопрос:\n",
    "        - \"Рекомендация: \"\"\"\n",
    "        \n",
    "        return PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "    def _setup_chain(self):\n",
    "        \n",
    "        memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "        \n",
    "        return LLMChain(llm=self.llm, prompt=self.prompt_template, memory=memory)\n",
    "\n",
    "    def handle_question(self, question):\n",
    "        response = self.chain.run(question=question)\n",
    "        hint = response.split(\"Рекомендация:\")[-1].strip().split(\"\\n\")[0]\n",
    "        return hint\n",
    "\n",
    "class DialogueMonitor:\n",
    "    def __init__(self, emotion_threshold=0.3, sentiment_threshold=-0.8, emotions_to_monitor=('angry', 'sad')):\n",
    "        self.emotion_threshold = emotion_threshold\n",
    "        self.sentiment_threshold = sentiment_threshold\n",
    "        self.emotions_to_monitor = emotions_to_monitor\n",
    "        \n",
    "        \n",
    "        model_checkpoint = 'cointegrated/rubert-tiny-sentiment-balanced'\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "        self.sentiment_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n",
    "        if torch.cuda.is_available():\n",
    "            self.sentiment_model.cuda()\n",
    "    \n",
    "    def get_sentiment(self, text):\n",
    "        with torch.no_grad():\n",
    "            inputs = self.tokenizer(\n",
    "                text,\n",
    "                return_tensors='pt',\n",
    "                truncation=True,\n",
    "                padding=True\n",
    "            ).to(self.sentiment_model.device)\n",
    "            logits = self.sentiment_model(**inputs).logits\n",
    "            proba = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "        label = self.sentiment_model.config.id2label[proba.argmax()]\n",
    "        score = proba.dot([-1, 0, 1])\n",
    "        return label, score\n",
    "    \n",
    "    def check_dialogue(self, segment_emotions, cumulative_emotions, text):\n",
    "        warnings = []\n",
    "        \n",
    "        \n",
    "        for emotion in self.emotions_to_monitor:\n",
    "            if segment_emotions['probabilities'].get(emotion, 0) > self.emotion_threshold:\n",
    "                warnings.append(f\"Segment {emotion} emotion above threshold\")\n",
    "        \n",
    "        \n",
    "        for emotion in self.emotions_to_monitor:\n",
    "            if cumulative_emotions['probabilities'].get(emotion, 0) > self.emotion_threshold:\n",
    "                warnings.append(f\"Cumulative {emotion} emotion above threshold\")\n",
    "        \n",
    "    \n",
    "        sentiment_label, sentiment_score = self.get_sentiment(text)\n",
    "        if sentiment_label == 'negative' and sentiment_score < self.sentiment_threshold:\n",
    "            warnings.append(f\"Strong negative sentiment detected (score: {sentiment_score:.2f})\")\n",
    "        \n",
    "        return warnings, sentiment_score\n",
    "\n",
    "class EmotionAnalyzer:\n",
    "    def __init__(self, emo_model):\n",
    "        self.emo_model = emo_model\n",
    "\n",
    "    def classify_emotion(self, audio_segment: np.ndarray, sample_rate: int) -> dict:\n",
    "        with torch.no_grad():\n",
    "            sf.write(\"temp_segment.wav\", audio_segment, sample_rate)\n",
    "            probs = self.emo_model.get_probs(\"temp_segment.wav\")[0]\n",
    "            emotion_probs = {self.emo_model.id2name[i]: p for i, p in enumerate(probs)}\n",
    "            dominant_emotion = max(emotion_probs, key=emotion_probs.get)\n",
    "        return {\"probabilities\": emotion_probs, \"dominant_emotion\": dominant_emotion}\n",
    "\n",
    "    @staticmethod\n",
    "    def update_cumulative_emotions(cumulative_emotions: dict, new_emotions: dict) -> dict:\n",
    "        if not cumulative_emotions:\n",
    "            return new_emotions.copy()\n",
    "        else:\n",
    "            updated = {}\n",
    "            for emotion in cumulative_emotions[\"probabilities\"]:\n",
    "                updated[emotion] = (cumulative_emotions[\"probabilities\"][emotion] + new_emotions[\"probabilities\"][emotion]) / 2\n",
    "            dominant_emotion = max(updated, key=updated.get)\n",
    "            return {\"probabilities\": updated, \"dominant_emotion\": dominant_emotion}\n",
    "\n",
    "    @staticmethod\n",
    "    def format_emotions(emotions: dict) -> str:\n",
    "        rounded_emotions = {k: round(v, 2) for k, v in emotions['probabilities'].items()}\n",
    "        return f\"Dominant: {emotions['dominant_emotion']} | {rounded_emotions}\"\n",
    "\n",
    "\n",
    "class ThemeHandler:\n",
    "    def __init__(self, config):\n",
    "        self.model_name = 'intfloat/multilingual-e5-small'\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = AutoModel.from_pretrained(self.model_name)\n",
    "        self.max_tokens = 512  \n",
    "        self.threshold = config['theme_deviation_threshold']\n",
    "        self.initial_buffer_seconds = config['initial_buffer_seconds']\n",
    "        self.sliding_window = []\n",
    "        self.goal_embedding = self.get_embedding(config['conversation_goal'])\n",
    "        self.current_embedding = None\n",
    "        self.total_duration = 0\n",
    "        self.buffer_passed = False\n",
    "\n",
    "    def get_embedding(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors='pt', truncation=True, max_length=self.max_tokens)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "    def format_dialogue_text(self, speaker, text):\n",
    "        return f\"{speaker} сказал: {text}\"\n",
    "\n",
    "    def update_sliding_window(self, formatted_text):\n",
    "        self.sliding_window.append(formatted_text)\n",
    "        combined_text = \" \".join(self.sliding_window)\n",
    "        tokens = self.tokenizer.tokenize(combined_text)\n",
    "        \n",
    "        while len(tokens) > self.max_tokens:\n",
    "            self.sliding_window.pop(0)\n",
    "            combined_text = \" \".join(self.sliding_window)\n",
    "            tokens = self.tokenizer.tokenize(combined_text)\n",
    "        \n",
    "        return combined_text\n",
    "\n",
    "    def update_embedding(self, speaker, text, segment_start, segment_end):\n",
    "        self.total_duration = segment_end\n",
    "        if not self.buffer_passed and self.total_duration >= self.initial_buffer_seconds:\n",
    "            self.buffer_passed = True\n",
    "        \n",
    "        formatted_text = self.format_dialogue_text(speaker, text)\n",
    "        sliding_window_text = self.update_sliding_window(formatted_text)\n",
    "        self.current_embedding = self.get_embedding(sliding_window_text)\n",
    "\n",
    "    def get_current_distance(self):\n",
    "        if self.current_embedding is None or not self.buffer_passed:\n",
    "            return None\n",
    "        return cosine(self.goal_embedding, self.current_embedding)\n",
    "\n",
    "    def check_theme_deviation(self):\n",
    "        deviation = self.get_current_distance()\n",
    "        if deviation is None:\n",
    "            return False, 0\n",
    "        return deviation >= self.threshold, deviation\n",
    "\n",
    "    def get_deviation_warning(self):\n",
    "        if not self.buffer_passed:\n",
    "            return None\n",
    "        is_deviated, deviation = self.check_theme_deviation()\n",
    "        if is_deviated:\n",
    "            return f\"Warning: Conversation has deviated from the initial theme. Deviation: {deviation:.2f}\"\n",
    "        return None\n",
    "\n",
    "    def get_status(self):\n",
    "        if not self.buffer_passed:\n",
    "            return f\"Accumulating initial data ({self.total_duration:.2f}/{self.initial_buffer_seconds:.2f} seconds)\"\n",
    "        return None\n",
    "\n",
    "\n",
    "class DialogueAnalyzer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        \n",
    "        self.downloader = YouTubeAudioDownloader(target_sr=config['target_sr'])\n",
    "        self.asr_model = self._load_asr_model()\n",
    "        self.pipeline = self._load_diarization_pipeline()\n",
    "        self.emo_model = self._load_emotion_model()\n",
    "        self.emotion_analyzer = EmotionAnalyzer(self.emo_model)\n",
    "        self.monitor = DialogueMonitor(**config['monitor_params'])\n",
    "        self.question_detector = QuestionDetector()\n",
    "        self.question_handler = QuestionHandler()\n",
    "        self.summarizer = DialogueSummarizer()\n",
    "        self.theme_handler = ThemeHandler(config)\n",
    "        self.intent_map = {\n",
    "            \"0\": \"Agreeing\",\n",
    "            \"1\": \"Arguing\",\n",
    "            \"2\": \"Asserting\",\n",
    "            \"3\": \"Assertive Questioning\", #question\n",
    "            \"4\": \"Challenging\",\n",
    "            \"5\": \"Default Illocuting\",\n",
    "            \"6\": \"Disagreeing\",\n",
    "            \"7\": \"Pure Questioning\", #question\n",
    "            \"8\": \"Restating\",\n",
    "            \"9\": \"Rhetorical Questioning\" #no\n",
    "        }\n",
    "        self.question_handler = QuestionHandler(knowledge_file=config['knowledge_file'])\n",
    "        \n",
    "    def _load_asr_model(self):\n",
    "        model = EncDecRNNTBPEModel.from_config_file(self.config['asr_config'])\n",
    "        ckpt = torch.load(self.config['asr_weights'], map_location=\"cpu\")\n",
    "        model.load_state_dict(ckpt, strict=False)\n",
    "        return model.eval().to(self.device)\n",
    "    \n",
    "    def _load_diarization_pipeline(self):\n",
    "        pipeline = Pipeline.from_pretrained(self.config['diarization_model'], use_auth_token=self.config['hf_token'])\n",
    "        return pipeline.to(self.device)\n",
    "    \n",
    "    def _load_emotion_model(self):\n",
    "        conf = OmegaConf.load(self.config['emo_config'])\n",
    "        model = GigaAMEmo(conf)\n",
    "        ckpt = torch.load(self.config['emo_weights'], map_location=\"cpu\")\n",
    "        model.load_state_dict(ckpt, strict=False)\n",
    "        return model.eval().to(self.device)\n",
    "    \n",
    "    def process_url(self, url):\n",
    "        try:\n",
    "            audio_path = self.downloader.download_and_convert(url)\n",
    "            \n",
    "            print(f\"Processed: {url}\")\n",
    "            print(f\"Audio saved to: {audio_path}\")\n",
    "            return audio_path\n",
    "        except Exception as e:\n",
    "            \n",
    "            print(f\"Failed to process {url}: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def audiosegment_to_numpy(audiosegment: AudioSegment) -> np.ndarray:\n",
    "        samples = np.array(audiosegment.get_array_of_samples())\n",
    "        if audiosegment.channels == 2:\n",
    "            samples = samples.reshape((-1, 2))\n",
    "        samples = samples.astype(np.float32, order=\"C\") / 32768.0\n",
    "        return samples\n",
    "\n",
    "    def segment_audio(self, audio_path: str) -> Tuple[List[np.ndarray], List[List[float]], List[str]]:\n",
    "        audio = AudioSegment.from_wav(audio_path)\n",
    "        diarization_results = self.pipeline(audio_path)\n",
    "        \n",
    "        segments = []\n",
    "        boundaries = []\n",
    "        speakers = []\n",
    "        curr_duration = 0\n",
    "        curr_start = 0\n",
    "        curr_end = 0\n",
    "        curr_speaker = None\n",
    "        \n",
    "        for turn, _, speaker in diarization_results.itertracks(yield_label=True):\n",
    "            start = max(0, turn.start)\n",
    "            end = min(len(audio) / 1000, turn.end)\n",
    "            \n",
    "            if (curr_duration > self.config['min_duration'] and start - curr_end > self.config['new_chunk_threshold']) or \\\n",
    "               (curr_duration + (end - curr_end) > self.config['max_duration']) or \\\n",
    "               (speaker != curr_speaker):\n",
    "                if curr_duration != 0:\n",
    "                    audio_segment = self.audiosegment_to_numpy(\n",
    "                        audio[int(curr_start * 1000) : int(curr_end * 1000)]\n",
    "                    )\n",
    "                    segments.append(audio_segment)\n",
    "                    boundaries.append([curr_start, curr_end])\n",
    "                    speakers.append(curr_speaker)\n",
    "                curr_start = start\n",
    "                curr_speaker = speaker\n",
    "            \n",
    "            curr_end = end\n",
    "            curr_duration = curr_end - curr_start\n",
    "\n",
    "        if curr_duration != 0:\n",
    "            audio_segment = self.audiosegment_to_numpy(\n",
    "                audio[int(curr_start * 1000) : int(curr_end * 1000)]\n",
    "            )\n",
    "            segments.append(audio_segment)\n",
    "            boundaries.append([curr_start, curr_end])\n",
    "            speakers.append(curr_speaker)\n",
    "\n",
    "        return segments, boundaries, speakers\n",
    "\n",
    "    @staticmethod\n",
    "    def format_time(seconds):\n",
    "        hours = int(seconds // 3600)\n",
    "        minutes = int((seconds % 3600) // 60)\n",
    "        seconds = seconds % 60\n",
    "        full_seconds = int(seconds)\n",
    "        milliseconds = int((seconds - full_seconds) * 100)\n",
    "        if hours > 0:\n",
    "            return f\"{hours:02}:{minutes:02}:{full_seconds:02}:{milliseconds:02}\"\n",
    "        else:\n",
    "            return f\"{minutes:02}:{full_seconds:02}:{milliseconds:02}\"\n",
    "    \n",
    "    def analyze_dialogue(self, audio_path):\n",
    "        full_audio, sample_rate = sf.read(audio_path)\n",
    "        segments, boundaries, speakers = self.segment_audio(audio_path)\n",
    "        transcriptions = self.asr_model.transcribe(segments, batch_size=self.config['batch_size'])[0]\n",
    "        \n",
    "        all_transcriptions = []\n",
    "        all_speakers = []\n",
    "        cumulative_emotions = None\n",
    "        \n",
    "        print(\"\\n--- Dialogue Analysis ---\\n\")\n",
    "        \n",
    "        for transcription, boundary, speaker in zip(transcriptions, boundaries, speakers):\n",
    "            if not transcription.strip():  \n",
    "                continue\n",
    "            \n",
    "            boundary_0 = self.format_time(boundary[0])\n",
    "            boundary_1 = self.format_time(boundary[1])\n",
    "            \n",
    "            start_sample = int(boundary[0] * sample_rate)\n",
    "            end_sample = int(boundary[1] * sample_rate)\n",
    "            audio_segment = full_audio[start_sample:end_sample]\n",
    "            \n",
    "            segment_emotions = self.emotion_analyzer.classify_emotion(audio_segment, sample_rate)\n",
    "            \n",
    "            if cumulative_emotions is None:\n",
    "                cumulative_emotions = segment_emotions.copy()\n",
    "            else:\n",
    "                cumulative_emotions = self.emotion_analyzer.update_cumulative_emotions(cumulative_emotions, segment_emotions)\n",
    "            \n",
    "            warnings, sentiment_score = self.monitor.check_dialogue(segment_emotions, cumulative_emotions, transcription)\n",
    "            \n",
    "            intent = self.question_detector.predict_intent(transcription)\n",
    "            intent_label = self.intent_map[str(intent)]\n",
    "            is_question = intent in self.question_detector.question_intents\n",
    "            \n",
    "            self.theme_handler.update_embedding(speaker, transcription, boundary[0], boundary[1])\n",
    "            theme_status = self.theme_handler.get_status()\n",
    "            theme_distance = self.theme_handler.get_current_distance()\n",
    "\n",
    "            theme_warning = self.theme_handler.get_deviation_warning()\n",
    "            if theme_warning:\n",
    "                warnings.append(theme_warning)\n",
    "            \n",
    "            print(f\"\\nTime: [{boundary_0} - {boundary_1}]\")\n",
    "            print(f\"Speaker: {speaker}\")\n",
    "            print(f\"Transcription: {transcription}\")\n",
    "            print(f\"Segment emotions: {self.emotion_analyzer.format_emotions(segment_emotions)}\")\n",
    "            print(f\"Cumulative emotions: {self.emotion_analyzer.format_emotions(cumulative_emotions)}\")\n",
    "            print(f\"Sentiment score: {sentiment_score:.2f}\")\n",
    "            print(f\"Intent: {intent_label}\")\n",
    "        \n",
    "            if theme_status:\n",
    "                print(f\"Theme status: {theme_status}\")\n",
    "            elif theme_distance is not None:\n",
    "                print(f\"Theme distance: {theme_distance:.2f}\")\n",
    "            \n",
    "            if warnings:\n",
    "                print(\"Warnings:\")\n",
    "                for warning in warnings:\n",
    "                    print(f\"- {warning}\")\n",
    "            \n",
    "            \n",
    "            if is_question:\n",
    "                hint = self.question_handler.handle_question(transcription)\n",
    "                print(\"\\nПодсказка для оператора:\")\n",
    "                print(hint)\n",
    "            \n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            all_transcriptions.append(transcription)\n",
    "            all_speakers.append(speaker)\n",
    "        \n",
    "        print(\"\\n--- Dialogue Summary ---\\n\")\n",
    "        summary = self.summarizer.summarize(all_transcriptions, all_speakers)\n",
    "        print(summary)\n",
    "        \n",
    "    def run(self, urls):\n",
    "        for url in urls:\n",
    "            audio_path = self.process_url(url)\n",
    "            if audio_path:\n",
    "                self.analyze_dialogue(audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Хорошая практика - выносить конфиг в отдельный файл, но решил оставить тут для наглядности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-28 19:55:19 mixins:172] Tokenizer SentencePieceTokenizer initialized with 512 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-07-28 19:55:20 audio_to_text_dataset:830] Could not load dataset as `manifest_filepath` was None. Provided config : {'shuffle': False, 'manifest_filepath': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-07-28 19:55:20 features:305] PADDING: 0\n",
      "[NeMo I 2024-07-28 19:55:22 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2024-07-28 19:55:22 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2024-07-28 19:55:22 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f085ff2306ef4b0ca5876209539756ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-07-28 19:55:35 nemo_logging:349] /home/dvulybi1/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFacePipeline`.\n",
      "      warn_deprecated(\n",
      "    \n",
      "[NeMo W 2024-07-28 19:55:35 nemo_logging:349] /home/dvulybi1/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "      warn_deprecated(\n",
      "    \n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77743c44dcc3406eb903aba9a50b3e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: https://youtu.be/gdEWuP2gIuA\n",
      "Audio saved to: /home/dvulybi1/vtb/downloads/gdEWuP2gIuA_mono_16000hz.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 100%|██████████| 4/4 [00:01<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dialogue Analysis ---\n",
      "\n",
      "\n",
      "Time: [00:01:97 - 00:04:31]\n",
      "Speaker: SPEAKER_01\n",
      "Transcription: александра евгеньевна здравствуйте\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.99, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.99, 'positive': 0.0}\n",
      "Sentiment score: 0.00\n",
      "Intent: Arguing\n",
      "Theme status: Accumulating initial data (4.32/25.00 seconds)\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [00:05:04 - 00:05:71]\n",
      "Speaker: SPEAKER_00\n",
      "Transcription: слушаю вас\n",
      "Segment emotions: Dominant: angry | {'angry': 0.69, 'sad': 0.0, 'neutral': 0.2, 'positive': 0.11}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.34, 'sad': 0.0, 'neutral': 0.6, 'positive': 0.06}\n",
      "Sentiment score: 0.01\n",
      "Intent: Arguing\n",
      "Theme status: Accumulating initial data (5.72/25.00 seconds)\n",
      "Warnings:\n",
      "- Segment angry emotion above threshold\n",
      "- Cumulative angry emotion above threshold\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [00:05:05 - 00:16:72]\n",
      "Speaker: SPEAKER_01\n",
      "Transcription: слушаю вас беспокоит вас центральное отделение втб банка меня зовут мария семь минут назад поступила заявка на изменение номера телефона операцию подтверждаете самостоятельно подавали заявку\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.84, 'positive': 0.16}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.17, 'sad': 0.0, 'neutral': 0.72, 'positive': 0.11}\n",
      "Sentiment score: -0.87\n",
      "Intent: Arguing\n",
      "Theme status: Accumulating initial data (16.72/25.00 seconds)\n",
      "Warnings:\n",
      "- Strong negative sentiment detected (score: -0.87)\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [00:17:66 - 00:20:68]\n",
      "Speaker: SPEAKER_00\n",
      "Transcription: опять двадцать пять ребята когда вас там разгонят а\n",
      "Segment emotions: Dominant: angry | {'angry': 1.0, 'sad': 0.0, 'neutral': 0.0, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: angry | {'angry': 0.58, 'sad': 0.0, 'neutral': 0.36, 'positive': 0.05}\n",
      "Sentiment score: -0.29\n",
      "Intent: Asserting\n",
      "Theme status: Accumulating initial data (20.69/25.00 seconds)\n",
      "Warnings:\n",
      "- Segment angry emotion above threshold\n",
      "- Cumulative angry emotion above threshold\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [00:21:90 - 00:22:37]\n",
      "Speaker: SPEAKER_01\n",
      "Transcription: зачем\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 1.0, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.29, 'sad': 0.0, 'neutral': 0.68, 'positive': 0.03}\n",
      "Sentiment score: -0.17\n",
      "Intent: Arguing\n",
      "Theme status: Accumulating initial data (22.37/25.00 seconds)\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [00:22:84 - 00:27:87]\n",
      "Speaker: SPEAKER_00\n",
      "Transcription: зачем зафигали уже тут разводить людей вот вас как зовут\n",
      "Segment emotions: Dominant: angry | {'angry': 0.89, 'sad': 0.0, 'neutral': 0.11, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: angry | {'angry': 0.59, 'sad': 0.0, 'neutral': 0.39, 'positive': 0.01}\n",
      "Sentiment score: -0.83\n",
      "Intent: Asserting\n",
      "Theme distance: 0.12\n",
      "Warnings:\n",
      "- Segment angry emotion above threshold\n",
      "- Cumulative angry emotion above threshold\n",
      "- Strong negative sentiment detected (score: -0.83)\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [00:28:48 - 00:29:66]\n",
      "Speaker: SPEAKER_01\n",
      "Transcription: так не отвечайте на звонок\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.85, 'positive': 0.15}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.3, 'sad': 0.0, 'neutral': 0.62, 'positive': 0.08}\n",
      "Sentiment score: -0.50\n",
      "Intent: Arguing\n",
      "Theme distance: 0.11\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [00:30:18 - 00:33:08]\n",
      "Speaker: SPEAKER_00\n",
      "Transcription: ну у вас вот у вас как вас зовут вот вас как зовут\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 1.0, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.15, 'sad': 0.0, 'neutral': 0.81, 'positive': 0.04}\n",
      "Sentiment score: 0.11\n",
      "Intent: Rhetorical Questioning\n",
      "Theme distance: 0.11\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [00:33:93 - 00:36:02]\n",
      "Speaker: SPEAKER_01\n",
      "Transcription: я вам только что представилась меня зовут мария\n",
      "Segment emotions: Dominant: positive | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.28, 'positive': 0.72}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.07, 'sad': 0.0, 'neutral': 0.54, 'positive': 0.38}\n",
      "Sentiment score: -0.01\n",
      "Intent: Asserting\n",
      "Theme distance: 0.11\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [00:36:05 - 00:42:97]\n",
      "Speaker: SPEAKER_00\n",
      "Transcription: ну предположим мария предположим вот мария вот вам не стыдно работать вот заниматься этим делом а\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 1.0, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.04, 'sad': 0.0, 'neutral': 0.77, 'positive': 0.19}\n",
      "Sentiment score: -0.91\n",
      "Intent: Arguing\n",
      "Theme distance: 0.10\n",
      "Warnings:\n",
      "- Strong negative sentiment detected (score: -0.91)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-07-28 19:55:52 nemo_logging:349] /home/dvulybi1/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "      warn_deprecated(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time: [00:44:26 - 00:45:69]\n",
      "Speaker: SPEAKER_01\n",
      "Transcription: нет а почему мне должно быть стыдно\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.99, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.02, 'sad': 0.0, 'neutral': 0.88, 'positive': 0.1}\n",
      "Sentiment score: -0.70\n",
      "Intent: Assertive Questioning\n",
      "Theme distance: 0.11\n",
      "\n",
      "Подсказка для оператора:\n",
      "1. Признайте чувства клиента. 2. Объясните причины, по которым ему не стоит стыдиться. 3. Предложите поддержку и помощь.\"\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [00:46:28 - 00:49:81]\n",
      "Speaker: SPEAKER_00\n",
      "Transcription: ну то есть вы считаете это нормальный способ заработка обманывать людей\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 1.0, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.01, 'sad': 0.0, 'neutral': 0.94, 'positive': 0.05}\n",
      "Sentiment score: -0.55\n",
      "Intent: Arguing\n",
      "Theme distance: 0.11\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [00:51:16 - 00:56:54]\n",
      "Speaker: SPEAKER_01\n",
      "Transcription: как вы считаете депутатам стыдно за то что они обманывают людей\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.89, 'positive': 0.11}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.01, 'sad': 0.0, 'neutral': 0.92, 'positive': 0.08}\n",
      "Sentiment score: -0.48\n",
      "Intent: Arguing\n",
      "Theme distance: 0.12\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [00:56:64 - 01:03:90]\n",
      "Speaker: SPEAKER_00\n",
      "Transcription: но вы занимаетесь чисто преступным вы оправдываете свои действия что другие делают что то похожее\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 1.0, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.96, 'positive': 0.04}\n",
      "Sentiment score: -0.58\n",
      "Intent: Asserting\n",
      "Theme distance: 0.13\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [01:03:26 - 01:10:36]\n",
      "Speaker: SPEAKER_01\n",
      "Transcription: я не оправдываю свои действия я задаю вам вопрос как вы думаете депутатам стыдно за то что они воруют у простых людей деньги\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.99, 'positive': 0.01}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.97, 'positive': 0.02}\n",
      "Sentiment score: -0.89\n",
      "Intent: Asserting\n",
      "Theme distance: 0.13\n",
      "Warnings:\n",
      "- Strong negative sentiment detected (score: -0.89)\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [01:11:66 - 01:13:96]\n",
      "Speaker: SPEAKER_00\n",
      "Transcription: ну вы считаете что все депутаты воруют\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 1.0, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.99, 'positive': 0.01}\n",
      "Sentiment score: -0.01\n",
      "Intent: Asserting\n",
      "Theme distance: 0.13\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [01:14:70 - 01:15:29]\n",
      "Speaker: SPEAKER_01\n",
      "Transcription: конечно\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 1.0, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.99, 'positive': 0.01}\n",
      "Sentiment score: 0.20\n",
      "Intent: Arguing\n",
      "Theme distance: 0.14\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [01:15:73 - 01:18:48]\n",
      "Speaker: SPEAKER_00\n",
      "Transcription: все безусловно все один до одного\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 1.0, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 1.0, 'positive': 0.0}\n",
      "Sentiment score: -0.85\n",
      "Intent: Asserting\n",
      "Theme distance: 0.14\n",
      "Warnings:\n",
      "- Strong negative sentiment detected (score: -0.85)\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [01:18:31 - 01:19:05]\n",
      "Speaker: SPEAKER_01\n",
      "Transcription: конечно\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 1.0, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 1.0, 'positive': 0.0}\n",
      "Sentiment score: 0.20\n",
      "Intent: Arguing\n",
      "Theme distance: 0.14\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [01:19:69 - 01:20:06]\n",
      "Speaker: SPEAKER_00\n",
      "Transcription: понятно\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 1.0, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 1.0, 'positive': 0.0}\n",
      "Sentiment score: 0.13\n",
      "Intent: Rhetorical Questioning\n",
      "Theme distance: 0.14\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [01:19:93 - 01:22:09]\n",
      "Speaker: SPEAKER_01\n",
      "Transcription: посмотрите сколько денег\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.98, 'positive': 0.02}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.99, 'positive': 0.01}\n",
      "Sentiment score: -0.01\n",
      "Intent: Assertive Questioning\n",
      "Theme distance: 0.14\n",
      "\n",
      "Подсказка для оператора:\n",
      "1. Уточните, о каких именно деньгах идет речь (например, сумма на счету, остаток на карте, баланс). 2. Предложите помощь в проверке баланса через систему интернет-банка или мобильное приложение. 3. Если возможно, предоставьте инструкцию по проверке баланса. 4. Если клиент не может проверить баланс самостоятельно, предложите помощь в этом процессе.\" \n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [01:20:38 - 01:28:99]\n",
      "Speaker: SPEAKER_00\n",
      "Transcription: вы поскольку поскольку вы считаете вы считаете что депутаты воруют вы считаете что у вас есть моральное право заниматься тем же самым\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 1.0, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.99, 'positive': 0.01}\n",
      "Sentiment score: -0.31\n",
      "Intent: Arguing\n",
      "Theme distance: 0.14\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [01:31:12 - 01:31:78]\n",
      "Speaker: SPEAKER_01\n",
      "Transcription: конечно\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.99, 'positive': 0.01}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.99, 'positive': 0.01}\n",
      "Sentiment score: 0.20\n",
      "Intent: Arguing\n",
      "Theme distance: 0.14\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [01:33:43 - 01:35:50]\n",
      "Speaker: SPEAKER_00\n",
      "Transcription: ну да если\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.99, 'positive': 0.01}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.99, 'positive': 0.01}\n",
      "Sentiment score: -0.03\n",
      "Intent: Rhetorical Questioning\n",
      "Theme distance: 0.14\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [01:35:35 - 01:38:22]\n",
      "Speaker: SPEAKER_01\n",
      "Transcription: она такая если даже депутаты воруют а почему я не могу\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.02, 'sad': 0.0, 'neutral': 0.98, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.01, 'sad': 0.0, 'neutral': 0.99, 'positive': 0.0}\n",
      "Sentiment score: -0.37\n",
      "Intent: Asserting\n",
      "Theme distance: 0.14\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [01:38:31 - 01:43:18]\n",
      "Speaker: SPEAKER_00\n",
      "Transcription: то есть все все нормально все должны друг у друга воровать это хорошо\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 1.0, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.99, 'positive': 0.0}\n",
      "Sentiment score: 0.92\n",
      "Intent: Arguing\n",
      "Theme distance: 0.15\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [01:43:87 - 01:46:34]\n",
      "Speaker: SPEAKER_01\n",
      "Transcription: но если даже депутаты воруют\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 1.0, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 1.0, 'positive': 0.0}\n",
      "Sentiment score: -0.01\n",
      "Intent: Asserting\n",
      "Theme distance: 0.15\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time: [01:46:34 - 02:00:65]\n",
      "Speaker: SPEAKER_00\n",
      "Transcription: да причем здесь депутаты перед богом вы же не депутатами станете ну перед своей совестью перед сами собой ну ладно и на меня нарвались нарветесь на какую нибудь многодетную семью украдите ее последние кровные\n",
      "Segment emotions: Dominant: angry | {'angry': 0.72, 'sad': 0.0, 'neutral': 0.27, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.36, 'sad': 0.0, 'neutral': 0.64, 'positive': 0.0}\n",
      "Sentiment score: -0.88\n",
      "Intent: Arguing\n",
      "Theme distance: 0.19\n",
      "Warnings:\n",
      "- Segment angry emotion above threshold\n",
      "- Cumulative angry emotion above threshold\n",
      "- Strong negative sentiment detected (score: -0.88)\n",
      "- Warning: Conversation has deviated from the initial theme. Deviation: 0.19\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [02:00:88 - 02:02:88]\n",
      "Speaker: SPEAKER_01\n",
      "Transcription: ну не ну не я так кто то другой\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.99, 'positive': 0.01}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.18, 'sad': 0.0, 'neutral': 0.81, 'positive': 0.01}\n",
      "Sentiment score: -0.60\n",
      "Intent: Arguing\n",
      "Theme distance: 0.19\n",
      "Warnings:\n",
      "- Warning: Conversation has deviated from the initial theme. Deviation: 0.19\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [02:03:30 - 02:03:97]\n",
      "Speaker: SPEAKER_00\n",
      "Transcription: понятно\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 1.0, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.09, 'sad': 0.0, 'neutral': 0.9, 'positive': 0.0}\n",
      "Sentiment score: 0.13\n",
      "Intent: Rhetorical Questioning\n",
      "Theme distance: 0.19\n",
      "Warnings:\n",
      "- Warning: Conversation has deviated from the initial theme. Deviation: 0.19\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [02:04:53 - 02:07:40]\n",
      "Speaker: SPEAKER_00\n",
      "Transcription: логика ваша понятна давайте удачи\n",
      "Segment emotions: Dominant: neutral | {'angry': 0.0, 'sad': 0.0, 'neutral': 1.0, 'positive': 0.0}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.05, 'sad': 0.0, 'neutral': 0.95, 'positive': 0.0}\n",
      "Sentiment score: -0.26\n",
      "Intent: Arguing\n",
      "Theme distance: 0.19\n",
      "Warnings:\n",
      "- Warning: Conversation has deviated from the initial theme. Deviation: 0.19\n",
      "--------------------------------------------------\n",
      "\n",
      "Time: [02:07:08 - 02:09:25]\n",
      "Speaker: SPEAKER_01\n",
      "Transcription: удачи спасибо\n",
      "Segment emotions: Dominant: positive | {'angry': 0.0, 'sad': 0.0, 'neutral': 0.08, 'positive': 0.92}\n",
      "Cumulative emotions: Dominant: neutral | {'angry': 0.02, 'sad': 0.0, 'neutral': 0.52, 'positive': 0.46}\n",
      "Sentiment score: 0.73\n",
      "Intent: Arguing\n",
      "Theme distance: 0.19\n",
      "Warnings:\n",
      "- Warning: Conversation has deviated from the initial theme. Deviation: 0.19\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Dialogue Summary ---\n",
      "\n",
      "SPEAKER_00 звонит в центральное отделение втб банка, чтобы узнать, что происходит с депутатами, воруют ли они у простых людей деньги, и задает вопрос о том, почему депутатам стыдно работать в этом деле, потому что у них есть моральное право заниматься этим.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    config = {\n",
    "        'hf_token': os.getenv['HF_TOKEN'],\n",
    "        'target_sr': 16000,\n",
    "        'asr_config': \"./rnnt_model_config.yaml\",\n",
    "        'asr_weights': \"./rnnt_model_weights.ckpt\",\n",
    "        'knowledge_file': './knowledge.txt',\n",
    "        'diarization_model': \"pyannote/speaker-diarization-3.1\",\n",
    "        'emo_config': \"emo_model_config.yaml\",\n",
    "        'emo_weights': \"emo_model_weights.ckpt\",\n",
    "        'monitor_params': {\n",
    "            'emotion_threshold': 0.3,\n",
    "            'sentiment_threshold': -0.8,\n",
    "            'emotions_to_monitor': ('angry', 'sad')\n",
    "        },\n",
    "        'batch_size': 10,\n",
    "        'max_duration': 22.0,\n",
    "        'min_duration': 15.0,\n",
    "        'new_chunk_threshold': 0.2,\n",
    "        'conversation_goal': \"подтверждение операции по заявке на изменение финансового номера телефона\",\n",
    "        'theme_deviation_threshold': 0.15,\n",
    "        'initial_buffer_seconds': 25\n",
    "    }\n",
    "    \n",
    "   \n",
    "    urls = [\n",
    "        #'https://youtu.be/UCLpgUjoExU',\n",
    "        'https://youtu.be/gdEWuP2gIuA'\n",
    "    ]\n",
    "   \n",
    "    analyzer = DialogueAnalyzer(config)\n",
    "    analyzer.run(urls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
